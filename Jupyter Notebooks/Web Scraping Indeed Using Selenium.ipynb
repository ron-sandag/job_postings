{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fafa6a52",
   "metadata": {},
   "source": [
    "# In this notebook, we will scrape job posting data from Indeed for Employment data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ce534",
   "metadata": {},
   "source": [
    "The majority of this project is based on this article by Bonnie Ma:\n",
    "https://towardsdatascience.com/web-scraping-job-postings-from-indeed-com-using-selenium-5ae58d155daf\n",
    "\n",
    "First, we import selenium and specify the driver path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc69a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "import os.path\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#specify driver path\n",
    "DRIVER_PATH = '/Users/rla/OneDrive - San Diego Association of Governments/Desktop/edgedriver_win64/msedgedriver'\n",
    "service = Service(DRIVER_PATH)\n",
    "driver = webdriver.Edge(service = service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d26b7a",
   "metadata": {},
   "source": [
    "Next, we need navigate to our target website (Indeed.com) and perform a search with the correct settings before we can begin scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d505037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the \"Find Jobs\" button to get search results\n",
    "#initial_search_button = driver.find_element(By.XPATH, '//*[@id=\"jobsearch\"]/button')\n",
    "\n",
    "#initial_search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d21b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the correct search settings\n",
    "\n",
    "#set the search radius to \"within 50 miles\" to cover San Diego County\n",
    "#filter_radius_button = driver.find_element(By.ID, \"filter-radius\")\n",
    "#filter_radius_button.click()\n",
    "#radius_menu = driver.find_element(By.ID, \"filter-radius-menu\")\n",
    "#fifty_mile_radius_button = radius_menu.find_element(By.XPATH, \".//li[6]\")\n",
    "#fifty_mile_radius_button.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca561191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#navigate to indeed.com\n",
    "# This webpage already has the search settings we are looking for\n",
    "driver.get('https://indeed.com/jobs?q=&l=San+Diego%2C+CA&radius=50&sort=date')\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed6ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_date(post_date, debug=False):\n",
    "    if debug:\n",
    "        print(post_date)\n",
    "    if post_date is None:\n",
    "        return None\n",
    "    x = re.search(r\"Today|Just posted|Posted\", post_date)\n",
    "    if (x):\n",
    "        days_past = 0\n",
    "    else:\n",
    "        x = re.search(r\"\\d+\", post_date)\n",
    "        days_past = int(x.group())\n",
    "\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    delta = datetime.timedelta(days=days_past)\n",
    "    final_date =(current_datetime-delta).date() \n",
    "    return final_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceaea37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#begin scraping data\n",
    "\n",
    "def web_scraper():\n",
    "    \n",
    "    #close the pop-up that appears\n",
    "    try:\n",
    "        close_popup = driver.find_element(By.ID, \"popover-x\")\n",
    "    except:\n",
    "        print(\"No pop-up found. Continuing\")\n",
    "    else:\n",
    "        close_popup.click()\n",
    "        driver.refresh()\n",
    "\n",
    "    titles=[]\n",
    "    names=[]\n",
    "    locations=[]\n",
    "    remotes=[]\n",
    "    salaries=[]\n",
    "    full_times=[]\n",
    "    part_times=[]\n",
    "    post_dates=[]\n",
    "\n",
    "    # *remember to align job categories with EDD data later*\n",
    "\n",
    "    #begin iterating through result pages\n",
    "\n",
    "    print(\"Begin scraping page\")\n",
    "    \n",
    "    try:\n",
    "        #let the driver wait 15 seconds to locate the element\n",
    "        # TODO: incorporate random wait time\n",
    "        driver.implicitly_wait(random.randrange(15,40))\n",
    "        job_card = driver.find_elements(By.XPATH, '//div[@class=\"job_seen_beacon\"]')\n",
    "    except:\n",
    "        driver.navigate().refresh()\n",
    "\n",
    "    for job in job_card:\n",
    "        #extract the job title\n",
    "        title = job.find_element(By.XPATH, './/td[@class=\"resultContent\"]/div/h2/span').text\n",
    "        titles.append(title)\n",
    "\n",
    "        #extract the company name\n",
    "        name = job.find_element(By.XPATH, './/span[@class=\"companyName\"]').text\n",
    "        names.append(name)    \n",
    "\n",
    "        #extract the company location\n",
    "        location = job.find_element(By.XPATH, './/div[@class=\"companyLocation\"]').text\n",
    "        locations.append(location)\n",
    "\n",
    "        #extract remote workplace information\n",
    "        x = re.search(r\"Remote\", location)\n",
    "        if (x):\n",
    "            remotes.append(True)\n",
    "        else:\n",
    "            remotes.append(False)\n",
    "\n",
    "        #extract metadata information\n",
    "        try:\n",
    "            metadata = job.find_element(By.XPATH, './/td[@class=\"resultContent\"]/div[3]').text\n",
    "            metadata = metadata.split(\"\\n\")\n",
    "        except:\n",
    "            metadata = None\n",
    "\n",
    "        #extract salary from metadata\n",
    "        salary=None\n",
    "        for data in metadata:\n",
    "            if '$' in data:\n",
    "                salary = data\n",
    "        salaries.append(salary)\n",
    "\n",
    "        #extract job type from metadata\n",
    "        full_time=False\n",
    "        part_time=False\n",
    "        for data in metadata:\n",
    "            if \"Full-time\" in data:\n",
    "                full_time = True\n",
    "            if \"Part-time\" in data:\n",
    "                part_time = True\n",
    "        full_times.append(full_time)\n",
    "        part_times.append(part_time)\n",
    "\n",
    "        #extract the job posting date\n",
    "        post_date = job.find_element(By.XPATH, '(.//span[@class=\"date\"])[last()]').text\n",
    "        \n",
    "        # Convert posted info into actual date\n",
    "        final_date = convert_text_to_date(post_date)\n",
    "        post_dates.append(final_date)\n",
    "\n",
    "    print(\"Finished scraping page\")\n",
    "    #put all the data into a DataFrame\n",
    "    job_postings_df = pd.DataFrame()\n",
    "    job_postings_df['Job Title'] = titles\n",
    "    job_postings_df['Company Name'] = names\n",
    "    job_postings_df['Location'] = locations\n",
    "    job_postings_df['Remote'] = remotes\n",
    "    job_postings_df['Salary'] = salaries\n",
    "    job_postings_df['Full Time'] = full_times\n",
    "    job_postings_df['Part Time'] = part_times\n",
    "    job_postings_df['Date Posted'] = post_dates\n",
    "\n",
    "    # Check to see if cumulative job posting file exists\n",
    "    file_path = '../Data/Job_posting_data_current.csv'\n",
    "    flag = os.path.isfile(file_path)\n",
    "    \n",
    "    if flag:\n",
    "        #open the cumulative CSV file as a DataFrame\n",
    "        old_df = pd.read_csv(file_path)\n",
    "        #append the DataFrames together\n",
    "        combined_job_posting_df = old_df.append(job_postings_df)\n",
    "    else:\n",
    "        combined_job_posting_df = job_postings_df\n",
    "    \n",
    "    #save the new DataFrame as a CSV file\n",
    "    print(\"Saving data\")\n",
    "    combined_job_posting_df.to_csv(file_path, index=False)\n",
    "    #job_postings_df.to_csv('Job_posting_data.csv', index=False)\n",
    "\n",
    "    #click for the next page of results\n",
    "    next_page_exists = True\n",
    "    try:\n",
    "        next_page = driver.find_element(By.XPATH, '//a[@aria-label=\"Next\"]//span[@class=\"np\"]')\n",
    "        print(\"Continuing to next page\\n\")\n",
    "        next_page.click()\n",
    "    except:\n",
    "        print(\"Unable to find next page arrow\\n\")\n",
    "        next_page_exists = False\n",
    "    return next_page_exists\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ec935bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 2\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 3\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 4\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 5\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 6\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 7\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 8\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 9\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 10\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 11\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 12\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 13\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 14\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 15\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 16\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 17\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 18\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 19\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 20\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 21\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 22\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 23\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 24\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 25\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 26\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 27\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 28\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 29\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 30\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 31\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 32\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 33\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 34\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 35\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 36\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 37\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 38\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 39\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 40\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 41\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 42\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 43\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 44\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 45\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 46\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 47\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 48\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 49\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 50\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 51\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 52\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 53\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 54\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 55\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 56\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Continuing to next page\n",
      "\n",
      "Scraping page 57\n",
      "No pop-up found. Continuing\n",
      "Begin scraping page\n",
      "Finished scraping page\n",
      "Saving data\n",
      "Unable to find next page arrow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "next_page_exists = True\n",
    "current_page = 1\n",
    "while next_page_exists:\n",
    "    print(\"Scraping page \" + str(current_page))\n",
    "    next_page_exists = web_scraper()\n",
    "    current_page += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0931f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Scraping finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf030e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
